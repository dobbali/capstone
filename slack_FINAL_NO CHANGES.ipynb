{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries imported\n"
     ]
    }
   ],
   "source": [
    "import params as p\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import punctuation\n",
    "import re\n",
    "import rake\n",
    "import data_aggregate as da\n",
    "import Rake_TF_IDF_Cleansing as bc\n",
    "import data_collection as dc\n",
    "import time\n",
    "import sys\n",
    "from slackclient import SlackClient\n",
    "from slacker import Slacker\n",
    "print('libraries imported')\n",
    "token ='xoxb-106983742324-cOVmqpTClEVkIpwcHxGY7x0X'\n",
    "slack = Slacker(token)\n",
    "sc = SlackClient(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combinedData_all_init = pd.read_excel(\"/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/Capstone_Demo/Data_Files/input_file.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slack_notify(message, name = '@textract'):\n",
    "    \n",
    "    if name:\n",
    "        return slack.chat.post_message(name, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/Capstone_Demo/Data_Files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prod_key_word(inputlist):\n",
    "    writer = pd.ExcelWriter('Keyword_Extract.xlsx')\n",
    "    for issue in inputlist:\n",
    "        df = pd.read_excel(path + issue + \".xlsx\")\n",
    "        df.to_excel(writer, issue)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textract(channel,issue_name_list):\n",
    "    \n",
    "    df_issue_list = []\n",
    "    for issue_name in issue_name_list:\n",
    "        tempdf = combinedData_all_init.loc[combinedData_all_init['issue_name'] == issue_name]\n",
    "        df_issue_list.append(tempdf)\n",
    "\n",
    "    combinedData_all = pd.concat(df_issue_list)\n",
    "    \n",
    "    combinedData_sample = combinedData_all.sample(frac= 1)\n",
    "    combinedData_sample = combinedData_sample.rename(index = str, columns={'incdnt_note_desc':'Chat','issue_name':'File_Name'})\n",
    "    if p.output == 'combined':\n",
    "        combinedData_sample['File_Name'] = 'issue'\n",
    "\n",
    "    combinedData_sample.drop(combinedData_sample.columns[[1]], axis=1, inplace=True)\n",
    "\n",
    "    message = 'Basic cleaning on data is done'\n",
    "    #t1 = datetime.datetime.now()\n",
    "    clean_df_rake = bc.basic_cleaning(combinedData_sample,'Chat',p.tf_idf_or_rake )\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "\n",
    "    message = 'Extracting customer chat in a list '\n",
    "    clean_df_rake['cust_chat'] = da.get_chat_df(clean_df_rake,'Chat',p.custoragent)\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "\n",
    "    message = 'Identified and removed address from Chat transcripts'\n",
    "    clean_df_rake['cust_chat'] = [bc.strip_address(lines,'/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/Capstone_Demo/Data_Files/state_names.txt') for lines in clean_df_rake['cust_chat']]\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "    \n",
    "    message = 'Removed One word sentences'\n",
    "    clean_df_rake['cust_chat'] = [bc.get_one_word(lines) for lines in clean_df_rake['cust_chat']]\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "\n",
    "    message = 'Removed Numbers'\n",
    "    clean_df_rake['cust_chat'] = [bc.strip_numbers_list(lines) for lines in clean_df_rake['cust_chat']]\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "\n",
    "    message ='Customer Chat in a Paragraph'\n",
    "    clean_df_rake['cust_chat'] = [da.combine_list_of_items(chat,'') for chat in clean_df_rake['cust_chat']]\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "\n",
    "    message = 'Customer Chat in a Single Paragraph for each issue'\n",
    "    just_chat = da.combine_list_of_items(list(clean_df_rake['cust_chat']),'')\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "    \n",
    "    message = \"Rake Cleaning done\"\n",
    "    dnew ={}\n",
    "    for item in set(clean_df_rake['File_Name']):\n",
    "        list_of_chat = list(clean_df_rake[clean_df_rake['File_Name'] == item]['cust_chat'])\n",
    "        dnew[\"{0}\".format(item)]= da.combine_list_of_items(list_of_chat,'')\n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,text=message, as_user=True)\n",
    "\n",
    "    df_issues = pd.DataFrame.from_dict(dnew, orient='index', dtype=None)\n",
    "    df_issues = df_issues.rename(index=str, columns={ 0 : \"Chat_Para_Customer\"})\n",
    "\n",
    "    if p.output == 'ind':\n",
    "        issue_list_names = list(set(clean_df_rake['File_Name']))\n",
    "    else:\n",
    "        issue_list_names = ['issue']\n",
    "    print(len(issue_list_names))\n",
    "    \n",
    "    rake_object = rake.Rake(p.path + \"SmartStoplist.txt\",p.min_word_len, p.min_word_phrase_len, p.freq)\n",
    "\n",
    "    writer = pd.ExcelWriter('Data_Files/Keyword_Extracted_R.xlsx')\n",
    "    for item in issue_list_names:\n",
    "        t1 = datetime.datetime.now()\n",
    "        sc.api_call(\"chat.postMessage\", channel=channel,text='Rake process started for ' + str(item), as_user=True)\n",
    "        chat_para = df_issues.loc[[item]]['Chat_Para_Customer'][0]\n",
    "        keywords_tuples = rake_object.run(chat_para)\n",
    "        df = pd.DataFrame(keywords_tuples)\n",
    "        df.to_excel(writer,str(item))\n",
    "        #df.to_excel( str(item) + '.xlsx')\n",
    "        t2 = datetime.datetime.now()\n",
    "        message = 'rake is done'\n",
    "        sc.api_call(\"chat.postMessage\", channel=channel,text= message + \" for \"+ str(item), as_user=True)\n",
    "    writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<@U34UXMU9J>\n",
      "StarterBot connected and running!\n",
      "<@U34UXMU9J> clubo\n",
      "None\n",
      "names and time stamps have not been removed\n",
      "1\n",
      "0:00:00.004759\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-62dc46f6bba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_slack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrtm_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mhandle_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_WEBSOCKET_DELAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-62dc46f6bba4>\u001b[0m in \u001b[0;36mhandle_command\u001b[0;34m(command, channel)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mcommand_list_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcommand_list_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0missues_list_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mtextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text extraction done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Keyword Extraction is DONE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-ad8812384d68>\u001b[0m in \u001b[0;36mtextract\u001b[0;34m(channel, issue_name_list)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chat.postMessage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Rake process started for '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_user\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mchat_para\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_issues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Chat_Para_Customer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mkeywords_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrake_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_para\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/text_analytics_automation/rake.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mslack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@manoj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Sentence Split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mphrase_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_candidate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__stop_words_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__min_char_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__max_words_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/text_analytics_automation/rake.py\u001b[0m in \u001b[0;36mgenerate_candidate_keywords\u001b[0;34m(sentence_list, stopword_pattern, min_char_length, max_words_length)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mphrase_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopword_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphrases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mdobbali/anaconda/lib/python3.5/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# starterbot's ID as an environment variable\n",
    "BOT_ID = \"U34UXMU9J\"\n",
    "\n",
    "# constants\n",
    "AT_BOT = \"<@\" + BOT_ID + \">\"\n",
    "print(AT_BOT)\n",
    "EXAMPLE_COMMAND = \"do\"\n",
    "date_pattern = re.compile('[0-9]{4}-[0-9]{2}-[0-9]{2}(,| |, )[0-9]{4}-[0-9]{2}-[0-9]{2}')\n",
    "x = 27429\n",
    "    \n",
    "greeting_list = ['hi','hello','are you there?','what can you do?','what do you do?','who are you?']\n",
    "size_sample = re.compile('^-?[0-9]+$')\n",
    "issues_list = \"Accessing_Account | ClubO | Coupon|\" \\\n",
    "        +\"International | Master_Card |\" \\\n",
    "        +\"Missing_Parts | Orders |\" \\\n",
    "        +\"Payments | Refund | Store_Card | Tracking\"\n",
    "        \n",
    "\n",
    "issues_list = [item.strip() for item in issues_list.split(\"|\")]\n",
    "issues_list = [item.lower() for item in issues_list]\n",
    "\n",
    "def handle_command(command, channel):\n",
    "    \"\"\"\n",
    "        Receives commands directed at the bot and determines if they\n",
    "        are valid commands. If so, then acts on the commands. If not,\n",
    "        returns back what it needs for clarification.\n",
    "    \"\"\"\n",
    "    response = \"Not sure what you mean.I am not that smart, YET. \\nIf you want to know legal commands, Try legal commands\"\n",
    "    attach = None\n",
    "               \n",
    "    if command.lower() in greeting_list:\n",
    "        response = \"Hi, I am Textrat. I can do Keyword extraction.\\nPlease enter start date and end date of data to be extracted seperated by comma\"\n",
    "        attach = [\n",
    "                             {\n",
    "                                            \"fallback\": \"Required plain-text summary of the attachment.\",\n",
    "                                            \"color\": \"#f74f40\",\n",
    "                                            \"pretext\": \"Here are few details about algorithm\",\n",
    "                                            \"author_name\": \"Manoj and Deepthi\",\n",
    "                                            \"title\": \"Keyword Extraction\",\n",
    "                                            \"text\": \"This will extract keywords from the data provided \",\n",
    "                                            \"fields\": [\n",
    "                                                {\n",
    "                                                    \"title\": \"Parameters requried\",\n",
    "                                                    \"value\": \"Date Range(YYYY-MM-DD),Sample size, issues\",\n",
    "                                                    \"short\": False\n",
    "                                                }\n",
    "                                            ]\n",
    "                                        }\n",
    "                                    ] \n",
    "        \n",
    "    if bool(date_pattern.match(command)):\n",
    "        date = command.split(',')\n",
    "        start_date = date[0]\n",
    "        end_date = date[1]\n",
    "        response =\"will extract data for \"+str(start_date)+\", \"+str(end_date)+\" What is the sample size that you want me to consider?\"\n",
    "        attach = None\n",
    "        \n",
    "    if bool(size_sample.match(command)):\n",
    "        frac_num = (int(command) / 22429)\n",
    "\n",
    "        response = \"Will extract data for requested sample size \" \n",
    "        \n",
    "        attach = [\n",
    "                                        {\n",
    "                                            \"fallback\": \"Required plain-text summary of the attachment.\",\n",
    "                                            \"color\": \"#f74f40\",\n",
    "                                            \"pretext\": \"These are the issues available\",\n",
    "                                            \"title\": \"List of Issues\",\n",
    "                                            \"text\": \"Accessing_Account | ClubO | Coupon|\\n\" \\\n",
    "        +\"International | Keyword_Extracted | Master_Card |\\n\" \\\n",
    "        +\"Missing_Parts | Orders|\\n\" \\\n",
    "        +\"Payments | Refund |Store_Card | Tracking\\n\"\n",
    "        +\"Select one or more issues seperated by comma\",\n",
    "                                            \"fields\": [\n",
    "                                                {\n",
    "                                                    \"title\": \"Select one or more issues\",\n",
    "                                                    \"value\": \"Eg: ClubO,Coupon,Orders,Refund\",\n",
    "                                                    \"short\": False\n",
    "                                                }\n",
    "                                            ]\n",
    "                                        }\n",
    "                                    ] \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    issues_list_set = set(issues_list)\n",
    "    command_list_set = set(command.split(\",\"))\n",
    "    if command_list_set.issubset(issues_list_set):\n",
    "        textract(channel,command.split(\",\"))\n",
    "        print(\"text extraction done\")\n",
    "        response = \"Keyword Extraction is DONE\"\n",
    "        prod_key_word(command.split(\",\"))\n",
    "        file_ad = \"/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/Capstone_Demo/Keyword_Extract_R.xlsx\"\n",
    "        slack.files.upload(file_ad, channels=channel)\n",
    "\n",
    "    if command == \"legal commands\":\n",
    "        response = \"There are the legal commands \\n Hi \\nHello,Are you there? \\nWho are you? \\nWhat do you do? \\nWhat can you do?\"\n",
    "        attach = None\n",
    "    \n",
    "        \n",
    "    \n",
    "    sc.api_call(\"chat.postMessage\", channel=channel,attachments = attach \n",
    "                          ,text=response, as_user=True)\n",
    "\n",
    "def parse_slack_output(slack_rtm_output):\n",
    "    \"\"\"\n",
    "        The Slack Real Time Messaging API is an events firehose.\n",
    "        this parsing function returns None unless a message is\n",
    "        directed at the Bot, based on its ID.\n",
    "    \"\"\"\n",
    "    output_list = slack_rtm_output\n",
    "    if output_list and len(output_list) > 0:\n",
    "        for output in output_list:\n",
    "            if output and 'text' in output and AT_BOT in output['text']:\n",
    "                # return text after the @ mention, whitespace removed\n",
    "                print(output['text'])\n",
    "                print(channel)\n",
    "                return output['text'].split(AT_BOT)[1].strip().lower(), \\\n",
    "                       output['channel']\n",
    "    return None, None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    READ_WEBSOCKET_DELAY = 1 # 1 second delay between reading from firehose\n",
    "    if sc.rtm_connect():\n",
    "        print(\"StarterBot connected and running!\")\n",
    "        while True:\n",
    "            command, channel = parse_slack_output(sc.rtm_read())\n",
    "            if command and channel:\n",
    "                handle_command(command, channel)\n",
    "            time.sleep(READ_WEBSOCKET_DELAY)\n",
    "    else:\n",
    "        print(\"Connection failed. Invalid Slack token or bot ID?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prod_key_word(inputlist):\n",
    "    writer = pd.ExcelWriter('Keyword_Extract.xlsx')\n",
    "    for issue in inputlist:\n",
    "        df = pd.read_excel(path + issue + \".xlsx\")\n",
    "        df.to_excel(writer, issue)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob # glob module finds all the pathnames matching a specified pattern\n",
    "path_list = glob.glob(path + \"*.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_list  =  [item.replace(\"/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/Capstone_Demo/Data_Files/\",'') for item in path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_list = [item.replace(\".xlsx\",'')for item in path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accessing_account',\n",
       " 'clubo',\n",
       " 'coupon',\n",
       " 'input_file',\n",
       " 'international',\n",
       " 'master_card',\n",
       " 'missing_parts',\n",
       " 'orders',\n",
       " 'payments',\n",
       " 'refund',\n",
       " 'store_card',\n",
       " 'tracking']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_list.remove('input_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_list.remove('~$Keyword_Extracted_R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accessing_account',\n",
       " 'clubo',\n",
       " 'coupon',\n",
       " 'international',\n",
       " 'master_card',\n",
       " 'missing_parts',\n",
       " 'orders',\n",
       " 'payments',\n",
       " 'refund',\n",
       " 'store_card',\n",
       " 'tracking']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod_key_word(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mdobbali/Google Drive/Overstock/Projects/cs_text_classification/Capstone_Demo'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
